{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten\n",
    "import os\n",
    "import matplotlib.image as mpimg\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "old_path = '/home/sergio/workspace/udacity/USDCN-project3_Behavioural_Cloning/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def fix_path(data_df):\n",
    "    cols = data_df.columns.tolist()\n",
    "    for col in data_df.columns:\n",
    "        try:\n",
    "            data_df[col] = data_df[col].apply(lambda x: x.replace(old_path, ''))\n",
    "        except:\n",
    "            pass\n",
    "    return data_df\n",
    "\n",
    "def preprocess(image):\n",
    "    # remove the sky and the car front\n",
    "    image = image[60:-25, :, :] \n",
    "    # resize image\n",
    "    image = cv2.resize(image, (IM_WIDTH, IM_HEIGHT), cv2.INTER_AREA)\n",
    "    # rgb2yuv this is what the nvvidia model does\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "    return image\n",
    "\n",
    "def augment_images(data_dir, center, left, right, steering_angle):\n",
    "    # Choose an image from left, center or right and adjust steering angle\n",
    "    choice = np.random.choice(3)\n",
    "    if choice == 0:\n",
    "        image = mpimg.imread(os.path.join(data_dir, left.strip()))\n",
    "        steering_angle += 0.2\n",
    "    elif choice == 1:\n",
    "        image = mpimg.imread(os.path.join(data_dir, right.strip()))\n",
    "        steering_angle -= 0.2\n",
    "    elif choice ==2:\n",
    "        image = mpimg.imread(os.path.join(data_dir, center.strip()))\n",
    "\n",
    "    # make a random flip on the image\n",
    "    if np.random.rand() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "        steering_angle = -steering_angle\n",
    "\n",
    "    return image, steering_angle\n",
    "\n",
    "def batch_generator(data_dir, image_paths, steering_angles, batch_size, is_training):\n",
    "    # Generate training image \n",
    "    images = np.empty([batch_size, IM_HEIGHT, IM_WIDTH, IM_CHANNELS])\n",
    "    steers = np.empty(batch_size)\n",
    "    while True:\n",
    "        i = 0\n",
    "        for index in np.random.permutation(image_paths.shape[0]):\n",
    "            center, left, right = image_paths[index]\n",
    "            steering_angle = steering_angles[index]\n",
    "            if is_training and np.random.rand() < 0.6:\n",
    "                # augment data when in training\n",
    "                image, steering_angle = augment_images(data_dir, center, left, right, steering_angle)\n",
    "            else:\n",
    "                # chooses image from center\n",
    "                image = mpimg.imread(os.path.join(data_dir, center.strip()))\n",
    "            # add image and steering angle\n",
    "            images[i] = preprocess(image)\n",
    "            steers[i] = steering_angle\n",
    "            i += 1\n",
    "            if i == batch_size:\n",
    "                break\n",
    "        yield images, steers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "IM_HEIGHT = 160\n",
    "IM_WIDTH = 320\n",
    "IM_CHANNELS = 3\n",
    "\n",
    "# load data\n",
    "data_dir = './data/'\n",
    "test_size = .20\n",
    "\n",
    "data_df = pd.read_csv(os.path.join(data_dir,'driving_log.csv'))\n",
    "data_df.columns = ['center','left','right','steering','throttle','break','speed']\n",
    "\n",
    "data_df = fix_path(data_df)\n",
    "\n",
    "X = data_df[['center', 'left', 'right']].values\n",
    "y = data_df['steering'].values\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=test_size, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# build keras model\n",
    "INPUT_SHAPE = (IM_HEIGHT, IM_WIDTH, IM_CHANNELS)\n",
    "keep_prob = .8\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x/127.5-1.0, input_shape=INPUT_SHAPE))\n",
    "model.add(Conv2D(24, 5, 5, activation='elu', subsample=(2, 2)))\n",
    "model.add(Conv2D(36, 5, 5, activation='elu', subsample=(2, 2)))\n",
    "model.add(Conv2D(48, 5, 5, activation='elu', subsample=(2, 2)))\n",
    "model.add(Conv2D(64, 3, 3, activation='elu'))\n",
    "model.add(Conv2D(64, 3, 3, activation='elu'))\n",
    "model.add(Dropout(keep_prob))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100, activation='elu'))\n",
    "model.add(Dense(50, activation='elu'))\n",
    "model.add(Dense(10, activation='elu'))\n",
    "model.add(Dense(1))\n",
    "model.summary()\n",
    "\n",
    "# train model\n",
    "learning_rate = 1.0e-4\n",
    "batch_size = 256\n",
    "samples_per_epoch = data_df.shape[0]*50/batch_size\n",
    "nb_epoch = 5\n",
    "\n",
    "checkpoint = ModelCheckpoint('model-{epoch:03d}.h5',\n",
    "                             monitor='val_loss',\n",
    "                             verbose=0,\n",
    "                             save_best_only=True,\n",
    "                             mode='auto')\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam(lr=learning_rate))\n",
    "\n",
    "model.fit_generator(batch_generator(data_dir, X_train, y_train, batch_size, True),\n",
    "                    samples_per_epoch,\n",
    "                    nb_epoch,\n",
    "                    max_q_size=1,\n",
    "                    validation_data = batch_generator(data_dir, X_valid, y_valid, batch_size, False),\n",
    "                    nb_val_samples=len(X_valid),\n",
    "                    callbacks=[checkpoint], \n",
    "                    verbose=1) \n",
    "print('saving')\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_generator = batch_generator(data_dir, X_train, y_train, batch_size, True)\n",
    "validation_generator = batch_generator(data_dir, X_valid, y_valid, batch_size, False)\n",
    "\n",
    "history_object = model.fit_generator(train_generator, samples_per_epoch =\n",
    "    len(X_train), validation_data = \n",
    "    validation_generator,\n",
    "    nb_val_samples = len(X_valid), \n",
    "    nb_epoch=5, verbose=1)\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
